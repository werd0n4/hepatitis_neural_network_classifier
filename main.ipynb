{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1OZGLE-JBRy2OacUR59jGiWcpQ8IQFY_m",
      "authorship_tag": "ABX9TyPqgPJHJnAq7x6KkpRmH5AA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDMEADcDuUu4"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNFrPcW63oE0"
      },
      "source": [
        "data_path = 'data/hepatitis.data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unk40AJ8lbAh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import clone\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "from tabulate import tabulate\n",
        "\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeYuN_houZ0t"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e29vMPgp3kwV"
      },
      "source": [
        "columns = ['class', 'age', 'sex', 'seroid', 'antviral',\n",
        "           'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_firm',\n",
        "           'spleen_palpable',  'spiders', 'ascites', 'varices', 'bilirubin', \n",
        "           'alk_phosphate', 'sgot', 'albumin', 'protime', 'histology']\n",
        "\n",
        "columns_to_drop = ['alk_phosphate', 'protime']\n",
        "\n",
        "df = pd.read_csv(data_path, names=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL5ceXqxvt1a"
      },
      "source": [
        "## Sanitize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FIPpDrknvGei",
        "outputId": "f6203fc9-e9db-478a-d86c-2e991b60f884"
      },
      "source": [
        "# drop columns with many empty records\n",
        "df = df.drop(columns_to_drop, axis=1)\n",
        "# mark '?' as NaN\n",
        "df = df[df != '?']\n",
        "# drop NaN\n",
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)\n",
        "# convert 'Object' type to floats and ints\n",
        "df[['bilirubin', 'sgot', 'albumin']] = df[['bilirubin', 'sgot', 'albumin']].astype('float')\n",
        "df[['class', 'sex', 'seroid', 'antviral', 'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_firm', 'spleen_palpable', 'spiders', 'ascites', 'varices', 'histology']] = df[['class', 'sex', 'seroid', 'antviral', 'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_firm', 'spleen_palpable', 'spiders', 'ascites', 'varices', 'histology']].astype(int)\n",
        "# replace class marks\n",
        "df.replace({1: 0, 2: 1}, inplace=True)\n",
        "# divdie df to X and y sets\n",
        "X = df.drop(['class'], axis=1)\n",
        "y = df['class']\n",
        "\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQbqjVW8xkI"
      },
      "source": [
        "# Features ranking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aCodMWQ4NQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55e8697-aad7-4596-e9cc-02ca178d7505"
      },
      "source": [
        "# use chi-squared test to make features ranking\n",
        "chi2_selector = SelectKBest(chi2, k=X.shape[1])\n",
        "data = chi2_selector.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYMY9MBtxKoA"
      },
      "source": [
        "## Ranking table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCk9pEdowQsg"
      },
      "source": [
        "# create ranking table\n",
        "chi2_scores = pd.DataFrame(list(zip(X.columns, chi2_selector.scores_)), columns=['feature', 'score'])\n",
        "chi2_scores = chi2_scores.round(2)\n",
        "chi2_scores = chi2_scores.sort_values('score', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUfoSDA3xOYh"
      },
      "source": [
        "## Bar plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "Jf9qfuadzr5p",
        "outputId": "0bf4cb14-564e-44bb-cdb4-33d267085c2a"
      },
      "source": [
        "# display bar plot\n",
        "plt.figure(figsize=(20,12))\n",
        "plt.rcParams['axes.facecolor'] = 'lightgray'\n",
        "plt.grid(zorder=0)\n",
        "estimator_num = len(chi2_scores['feature'])\n",
        "\n",
        "# sort ascending because horizontal bars print in reverse order\n",
        "ascending_features = chi2_scores.sort_values('score', ascending=True)\n",
        "\n",
        "# create horizontal bar plot\n",
        "plt.barh(range(estimator_num), ascending_features['score'], align='center', zorder=3, edgecolor='black')\n",
        "\n",
        "# label bars and axis\n",
        "plt.yticks(range(estimator_num), ascending_features['feature'])\n",
        "plt.title('Ranking based on chi-squared test')\n",
        "plt.ylabel('Features')\n",
        "plt.xlabel('Chi-squared test value')\n",
        "\n",
        "# add scores at bars end\n",
        "for i, v in enumerate(ascending_features['score']):\n",
        "    plt.text(v + 0.6, i - 0.1, str(v), color='blue', fontweight='bold')\n",
        "\n",
        "# save to file must be call before show\n",
        "plt.savefig(fname='ranking.png', orientation='landscape')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cp3DAIP80R0"
      },
      "source": [
        "# chi2_support = chi2_selector.get_support()\n",
        "# chi2_feature = X.loc[:,chi2_support].columns.tolist()\n",
        "# print(chi2_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VsNC748Eia_"
      },
      "source": [
        "# X_norm_striped = MinMaxScaler().fit_transform(X[chi2_feature])\n",
        "# df = pd.DataFrame(data=X[chi2_feature], columns=chi2_feature)\n",
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Experimental environment"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "4hC0ttSAIBsF"
      }
    },
    {
      "source": [
        "### Classifiers declaration"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clfs = {\n",
        "    '512_momentum': MLPClassifier(hidden_layer_sizes=512, verbose=True, max_iter=500, early_stopping=True, n_iter_no_change=20, solver='sgd',momentum=0.9),\n",
        "    '256_momentum': MLPClassifier(hidden_layer_sizes=256, verbose=True, max_iter=500, early_stopping=True, n_iter_no_change=20, solver='sgd',momentum=0.9),\n",
        "    '128_momentum': MLPClassifier(hidden_layer_sizes=128, verbose=True, max_iter=500, early_stopping=True, n_iter_no_change=20, solver='sgd',momentum=0.9),\n",
        "    '512_no_momentum': MLPClassifier(hidden_layer_sizes=512, verbose=True, max_iter=500, early_stopping=True, n_iter_no_change=20, solver='adam', momentum=0),\n",
        "    '256_no_momentum': MLPClassifier(hidden_layer_sizes=256, verbose=True, max_iter=500, early_stopping=True, n_iter_no_change=20, solver='adam', momentum=0),\n",
        "    '128_no_momentum': MLPClassifier(hidden_layer_sizes=128, verbose=True, max_iter=500, early_stopping=True, n_iter_no_change=20, solver='adam', momentum=0)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_splits = 2\n",
        "n_repeats = 5\n",
        "number_of_features = len(X.columns)\n",
        "clfs_amount = len(clfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result of every single k-fold \n",
        "accuracy_scores = np.zeros((len(clfs), number_of_features, n_splits * n_repeats))"
      ]
    },
    {
      "source": [
        "### Model fitting with cross validation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "\n",
        "for features_index in range(number_of_features):\n",
        "    k_best_selector = SelectKBest(chi2, k=features_index + 1)\n",
        "    selected_data = k_best_selector.fit_transform(X, y)\n",
        "\n",
        "    for fold_id, (train_index, test_index) in enumerate(rskf.split(selected_data, y)):\n",
        "        for clf_id, clf_name in enumerate(clfs):\n",
        "            X_train, X_test = selected_data[train_index], selected_data[test_index]\n",
        "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "            clf = clfs[clf_name]\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "            accuracy_scores[clf_id, features_index, fold_id] = accuracy_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "means = np.mean(accuracy_scores, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Classifier, features, k-fold mean ===\")\n",
        "for clf_id, clf_name in enumerate(clfs):\n",
        "    print(f\"--- Classifier: {clf_name} ---\")\n",
        "    for feature_index in range(number_of_features):\n",
        "        cls_mean = means[clf_id,feature_index]\n",
        "        print(\"Features: %d, mean: %.4f\" % (feature_index+1, cls_mean))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "means.shape"
      ]
    },
    {
      "source": [
        "## Plots"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### Plots with momentum"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display bar plot\n",
        "plt.figure(figsize=(20,12))\n",
        "plt.rcParams['axes.facecolor'] = 'lightgray'\n",
        "plt.grid(zorder=0)\n",
        "\n",
        "plot_x = np.arange(1, number_of_features+1)\n",
        "# create horizontal bar plot\n",
        "# plt.barh(range(estimator_num), ascending_features['score'], align='center', zorder=3, edgecolor='black')\n",
        "colors = ['red', 'green', 'blue']\n",
        "for clf_id, clf_name in enumerate(clfs):\n",
        "    if clf_id < 3: # only with momentum\n",
        "        plt.plot(plot_x, means[clf_id], colors[clf_id])\n",
        "\n",
        "# label bars and axis\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([1,number_of_features])\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.xticks(np.arange(1, number_of_features+1, 1))\n",
        "plt.title('Means scores with momentum')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of features')\n",
        "\n",
        "red_patch = mpatches.Patch(color='red', label='Neurons: 512')\n",
        "green_patch = mpatches.Patch(color='green', label='Neurons: 256')\n",
        "blue_patch = mpatches.Patch(color='blue', label='Neurons: 128')\n",
        "legend_patches=[red_patch,green_patch,blue_patch]\n",
        "\n",
        "# save to file must be call before show\n",
        "plt.savefig(fname='means-with-momentum.png', orientation='landscape')\n",
        "plt.legend(handles=legend_patches,loc=4)\n",
        "plt.show()\n"
      ]
    },
    {
      "source": [
        "### Plots without momentum"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display bar plot\n",
        "plt.figure(figsize=(20,12))\n",
        "plt.rcParams['axes.facecolor'] = 'lightgray'\n",
        "plt.grid(zorder=0)\n",
        "\n",
        "plot_x = np.arange(1, number_of_features+1)\n",
        "# create horizontal bar plot\n",
        "# plt.barh(range(estimator_num), ascending_features['score'], align='center', zorder=3, edgecolor='black')\n",
        "colors = ['red', 'green', 'blue']\n",
        "for clf_id, clf_name in enumerate(clfs):\n",
        "    if clf_id < 3: # only with no momentum\n",
        "        plt.plot(plot_x, means[clf_id+3], colors[clf_id])\n",
        "\n",
        "# label bars and axis\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([1,number_of_features])\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "plt.xticks(np.arange(1, number_of_features+1, 1))\n",
        "plt.title('Means scores without momentum')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of features')\n",
        "\n",
        "red_patch = mpatches.Patch(color='red', label='Neurons: 512')\n",
        "green_patch = mpatches.Patch(color='green', label='Neurons: 256')\n",
        "blue_patch = mpatches.Patch(color='blue', label='Neurons: 128')\n",
        "legend_patches=[red_patch,green_patch,blue_patch]\n",
        "\n",
        "# save to file must be call before show\n",
        "plt.savefig(fname='means-without-momentum.png', orientation='landscape')\n",
        "plt.legend(handles=legend_patches,loc=4)\n",
        "plt.show()"
      ]
    },
    {
      "source": [
        "# Statistical analysis "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_statistics = np.zeros((number_of_features, clfs_amount, clfs_amount))\n",
        "p_values = np.zeros((number_of_features, clfs_amount, clfs_amount))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "for feat in range(number_of_features): # we compare every classifier with each other for every feature number\n",
        "    for cls_a in range(clfs_amount):\n",
        "        for cls_b in range(clfs_amount):\n",
        "            a = accuracy_scores[cls_a][feat]\n",
        "            b = accuracy_scores[cls_b][feat]\n",
        "            t_statistics[feat][cls_a][cls_b], p_values[feat][cls_a][cls_b] = ttest_ind(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "\n",
        "t_statistics = np.round(t_statistics, 2)\n",
        "p_values = np.round(p_values, 2)\n",
        "\n",
        "for feat in range(number_of_features): \n",
        "    print(f\"=== Number of features: {feat} ===\")\n",
        "    for clf_a_id, clf_a_name in enumerate(clfs):\n",
        "        for clf_b_id, clf_b_name in enumerate(clfs):\n",
        "            print(f'\\tClassifier {clf_a_name} compare to {clf_b_name}:')\n",
        "            print(f'\\tstatistic = {t_statistics[feat][clf_a_id][clf_b_id]}, pvalue = {p_values[feat][clf_a_id][clf_b_id]}')\n",
        "            print()\n",
        "\n"
      ]
    },
    {
      "source": [
        "### Display results"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "headers = [key for key in clfs.keys()]\n",
        "\n",
        "for feat in range(0, number_of_features):\n",
        "    print(f'=== T-test results for {feat+1} features ===')\n",
        "    table_to_print = []\n",
        "    one_row = []\n",
        "    for clf_a_id, clf_a_name in enumerate(clfs):\n",
        "        one_row.append(clf_name)\n",
        "        for clf_b_id, clf_b_name in enumerate(clfs):\n",
        "            tmp = 's: ' + str(t_statistics[feat][clf_a_id][clf_b_id]) + ', p: ' + str(p_values[feat][clf_a_id][clf_b_id])\n",
        "            one_row.append(tmp)\n",
        "        table_to_print.append(one_row)\n",
        "        one_row = []\n",
        "    print(tabulate(table_to_print, headers))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}